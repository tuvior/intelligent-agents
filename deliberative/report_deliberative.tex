\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{textcomp}

% Add other packages here %


% Put your group number and names in the author field %
\title{\bf Excercise 3\\ Implementing a deliberative Agent}
\author{Group \textnumero : Student 1, Student 2}


% N.B.: The report should not be longer than 3 pages %


\begin{document}
\maketitle

\section{Model Description}

\subsection{Intermediate States}
% Describe the state representation %
We decided to represent a state by the following attributes: 
\begin{itemize}
	\item The current city of the agent
	\item The cost paid to reach this state, defined as being \textit{distance x cost/kilometer}
	\item The weight carried by the agent, defined as being the sum of the weight of the tasks carried
	\item The set of carried tasks
	\item The set of available tasks
\end{itemize}

The implementation in Java of such states will be described in the BFS and A* implementations discussion.

\subsection{Goal State}
% Describe the goal state %
An agent has completed its duty when all the original available tasks have been picked up and delivered to their respective cities. Thus, in our implementation, a goal state is a state with an empty set of available tasks and an empty set of carried tasks. 

\subsection{Actions}
% Describe the possible actions/transitions in your model %
At each state, an agent can execute several actions. However, we restricted these actions by assigning priorities, in order to reduce the number of generated state and optimise the overall algorithm. The possible actions, sorted by priority, are the following:

\begin{enumerate}
	\item \textit{Deliver}: if the world is in a state in which the agent can deliver a task in the current city, it will be the next action.
	\item \textit{Pick-up}: if the world is in a state in which the agent can pick up a task in the current city, it will be the next action.
	\item \textit{Move}: otherwise, an action is generated for each possible move to a city where a task can be delivered or picked up. This will be translated in several moves, along the path to the destination city, during the plan generation later on.
\end{enumerate}

We chose to implement those optimisation in order to avoid generating extra state which won't lead to an optimal goal state. In this direction, it does not make sense to not deliver a task as soon as it is possible, or similarly pick up a task. If the agent has to move, then generating a move for all the neighbours is not optimal since it is equivalent to move randomly on the map: we only generate path to cities where it's possible to deliver or pick up a task.

These optimisations highly improved the plan generation time, since the graph is much small. 

\section{Implementation}

\subsection{BFS and A*}
Note that we decided to group implementation descriptions since they are using the same data structures. Only the algorithm itself will change, but it's essentially the same as in the slides. 

Our implementation associates a state with a graph node, grouping all the state attributes, in the \textit{Node} class. The class contains the \textit{getSuccessors} method, responsible for generating all the next possible states following the criterias stated above. 

Then, during BFS and A*, we generate the graph on the fly and search for goal states. All the generated nodes remember their parent states in order to be able to go back to the root from the optimal goal state. Then, we can generate the plan by going from the root to the final goal state, collecting all the actions taken along the path. This is done thanks to references left along the way, while going back up the tree. 

The major difference between BFS and A* is that BFS won't stop when finding a goal state, since another one can stand below the current level. Then we have to keep the current best state, and search for the optimal one in the whole graph. For A*, since we visit nodes in an optimal order (defined by the heuristic), by we guaranteed to find the optimal goal state as soon as we find the first one. 

\subsection{Heuristic Function}
The heuristic function used in A* corresponds to a lower bound to the maximum future cost the current branch will have to spend to complete all it's tasks, and is obtained by calculating what the maximum distance would be travelled to either deliver the furthest carried tasks carried or to pickup \textbf{and} deliver the furthest available task.

Being this heuristic a lower bound of the \textit{true} value of the goal state optimality is maintained, it is impossible to assign a higher value to a node than the one that would be its true value.


\section{Results}

\subsection{Experiment 1: BFS and A* Comparison}
% Compare the two algorithms in terms of: optimality, efficiency, limitations %
% Report the number of tasks for which you can build a plan in less than one minute %

\subsubsection{Setting}
% Describe the settings of your experiment: topology, task configuration, etc. %

This experiment has been performed on the Swiss topology, and all other settings are default as given.

\subsubsection{Observations}
Both algorithms correctly find the optimal solution to the problem.

A*, as expected, turns out to be largely more efficient than BFS, the execution time and memory requirements quickly explode for the latter, as much bigger tree is constructed during the search.
The execution time of BFS could be dropped in the case where we would not care about optimality of the solution, i.e. using the first goal state found by the algorithm as plan. Unfortunately this can easily result in very unoptimized plans.

Maximum tasks handled by \textbf{BFS} in under a minute: 13 (44 seconds)\\
Maximum tasks handled by \textbf{A*} in under a minute: 25 (42 seconds)\\
(experiments made on a ThinkPad t460s, not exactly the most powerful of CPUs)



\subsection{Experiment 2: Multi-agent Experiments}
% Observations in multi-agent experiments %

\subsubsection{Setting}
Experiments made on Swiss topology with default settings, 15 tasks available and 3 agents.

\subsubsection{Observations}
It is clear from this experiment how important it will be to coordinate multiple agents in future projects. In this case agents \textit{steal} tasks from each other without logic and end up having to travel the same path at the same time to deliver different tasks, while if the tasks would have been split intelligently this could have been avoided.

\end{document}